{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR from Scratch\n",
    "\n",
    "## This notebook implements SimCLR end‑to‑end\n",
    "\n",
    "1. Build augmentations\n",
    "\n",
    "2. Build the SimCLR model\n",
    "\n",
    "3. Implement NT‑Xent loss\n",
    "\n",
    "4. Train on STL‑10 (unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import STL10\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SimCLR Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:57:39.892856Z",
     "iopub.status.busy": "2025-12-18T14:57:39.891860Z",
     "iopub.status.idle": "2025-12-18T14:57:39.900092Z",
     "shell.execute_reply": "2025-12-18T14:57:39.899367Z",
     "shell.execute_reply.started": "2025-12-18T14:57:39.892807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimCLRAugmentations:\n",
    "    def __init__(self, image_size=96):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(image_size),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.GaussianBlur(kernel_size=9),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        v1 = self.transform(x)\n",
    "        v2 = self.transform(x)\n",
    "        return v1, v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:57:46.447560Z",
     "iopub.status.busy": "2025-12-18T14:57:46.447062Z",
     "iopub.status.idle": "2025-12-18T14:57:46.451963Z",
     "shell.execute_reply": "2025-12-18T14:57:46.451238Z",
     "shell.execute_reply.started": "2025-12-18T14:57:46.447531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class STL10SimCLR(STL10):\n",
    "    def __init__(self, *args, simclr_transform=None, **kwargs):\n",
    "        super().__init__(*args, transform=None, **kwargs)\n",
    "        self.simclr_transform = simclr_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, _ = super().__getitem__(index)  # raw PIL image\n",
    "        v1, v2 = self.simclr_transform(img)\n",
    "        return v1, v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SimCLR Model\n",
    "2.1 simclr model\n",
    "2.2 projection head (mlp layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:58:46.995795Z",
     "iopub.status.busy": "2025-12-18T14:58:46.995387Z",
     "iopub.status.idle": "2025-12-18T14:58:47.001242Z",
     "shell.execute_reply": "2025-12-18T14:58:47.000514Z",
     "shell.execute_reply.started": "2025-12-18T14:58:46.995760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, projection_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = models.resnet18(weights=None)\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        \n",
    "        \n",
    "        self.projection_head = ProjectionHead(\n",
    "            input_dim=512,\n",
    "            hidden_dim=512,\n",
    "            output_dim=projection_dim\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projection_head(h)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:57:51.833785Z",
     "iopub.status.busy": "2025-12-18T14:57:51.833106Z",
     "iopub.status.idle": "2025-12-18T14:57:51.838165Z",
     "shell.execute_reply": "2025-12-18T14:57:51.837531Z",
     "shell.execute_reply.started": "2025-12-18T14:57:51.833756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return F.normalize(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. NT-XENT Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:57:53.812464Z",
     "iopub.status.busy": "2025-12-18T14:57:53.812176Z",
     "iopub.status.idle": "2025-12-18T14:57:53.818299Z",
     "shell.execute_reply": "2025-12-18T14:57:53.817506Z",
     "shell.execute_reply.started": "2025-12-18T14:57:53.812438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    \n",
    "    def forward(self, z):\n",
    "        batch_size = z.shape[0] // 2\n",
    "        sim = torch.matmul(z, z.T) / self.temperature\n",
    "        \n",
    "        \n",
    "        mask = torch.eye(2 * batch_size, device=z.device).bool()\n",
    "        sim.masked_fill_(mask, -9e15)\n",
    "        \n",
    "        \n",
    "        positives = torch.cat([\n",
    "        torch.diag(sim, batch_size),\n",
    "        torch.diag(sim, -batch_size)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        labels = torch.zeros(2 * batch_size, dtype=torch.long, device=z.device)\n",
    "        loss = F.cross_entropy(sim, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train on SimCLR \n",
    "4.1 load dataset\n",
    "4.2 training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:57:56.257613Z",
     "iopub.status.busy": "2025-12-18T14:57:56.257312Z",
     "iopub.status.idle": "2025-12-18T14:58:02.456157Z",
     "shell.execute_reply": "2025-12-18T14:58:02.455575Z",
     "shell.execute_reply.started": "2025-12-18T14:57:56.257571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = SimCLRAugmentations(image_size=96)\n",
    "\n",
    "dataset = STL10SimCLR(\n",
    "    root=\"./data\",\n",
    "    split=\"unlabeled\",\n",
    "    download=True,\n",
    "    simclr_transform=transform\n",
    ")\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:58:06.585506Z",
     "iopub.status.busy": "2025-12-18T14:58:06.585219Z",
     "iopub.status.idle": "2025-12-18T14:58:06.766193Z",
     "shell.execute_reply": "2025-12-18T14:58:06.765622Z",
     "shell.execute_reply.started": "2025-12-18T14:58:06.585479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SimCLR().to(device)\n",
    "loss_fn = NTXentLoss(temperature=0.5)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T14:58:50.871978Z",
     "iopub.status.busy": "2025-12-18T14:58:50.871430Z",
     "iopub.status.idle": "2025-12-18T14:58:54.832575Z",
     "shell.execute_reply": "2025-12-18T14:58:54.831549Z",
     "shell.execute_reply.started": "2025-12-18T14:58:50.871946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79f39a17e700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x79f39a17e700>^^\n",
      "^Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "^^    ^self._shutdown_workers()^\n",
      "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "^^    ^if w.is_alive():^\n",
      "^ ^ ^ ^ ^ ^ ^ ^^^\n",
      "^AssertionError^^: can only test a child process^\n",
      "^^^^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79f39a17e700>\n",
      "\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "Traceback (most recent call last):\n",
      "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "   self._shutdown_workers() \n",
      "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "       if w.is_alive():  \n",
      "  ^  ^^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^^ ^ ^ ^  \n",
      "AssertionError :   can only test a child process \n",
      "  ^^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79f39a17e700>^^\n",
      "Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "^^    ^self._shutdown_workers()^^\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "^    ^if w.is_alive():^\n",
      "^ ^ ^ ^ ^ ^^ ^ ^^^^^^^^^^^^^^\n",
      "^AssertionError^: ^can only test a child process\n",
      "^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Module [SimCLR] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/445915222.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \"\"\"\n\u001b[0;32m--> 399\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;34mf'Module [{type(self).__name__}] is missing the required \"forward\" function'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [SimCLR] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for v1, v2 in loader:\n",
    "        v1 = v1.to(device)\n",
    "        v2 = v2.to(device)\n",
    "        \n",
    "        z1 = model(v1)\n",
    "        z2 = model(v2)\n",
    "        z = torch.cat([z1, z2], dim=0)\n",
    "        \n",
    "        loss = loss_fn(z)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
