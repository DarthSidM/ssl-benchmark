{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BYOL from Scratch\n\n## This notebook implements BYOL end‑to‑end\n\n1. Build augmentations\n\n2. Build the BYOL model\n\n3. Train on STL‑10 (unlabeled)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.datasets import STL10\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:51:28.981715Z","iopub.execute_input":"2025-12-19T04:51:28.982010Z","iopub.status.idle":"2025-12-19T04:51:35.721356Z","shell.execute_reply.started":"2025-12-19T04:51:28.981983Z","shell.execute_reply":"2025-12-19T04:51:35.720588Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# 1. BYOL Augmentations","metadata":{}},{"cell_type":"code","source":"class BYOLAugmentations:\n    def __init__(self, image_size=96):\n        self.transform = transforms.Compose([\n            transforms.RandomResizedCrop(image_size),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n            ], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.GaussianBlur(kernel_size=9),\n            transforms.ToTensor(),\n        ])\n\n\n    def __call__(self, x):\n        v1 = self.transform(x)\n        v2 = self.transform(x)\n        return v1, v2\n\nbyol_transform = BYOLAugmentations()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:51:35.722621Z","iopub.execute_input":"2025-12-19T04:51:35.723147Z","iopub.status.idle":"2025-12-19T04:51:35.728715Z","shell.execute_reply.started":"2025-12-19T04:51:35.723108Z","shell.execute_reply":"2025-12-19T04:51:35.727998Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class STL10BYOL(STL10):\n    def __init__(self, *args, simclr_transform=None, **kwargs):\n        super().__init__(*args, transform=None, **kwargs)\n        self.simclr_transform = simclr_transform\n\n    def __getitem__(self, index):\n        img, _ = super().__getitem__(index)  # raw PIL image\n        v1, v2 = self.simclr_transform(img)\n        return v1, v2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:51:35.729514Z","iopub.execute_input":"2025-12-19T04:51:35.729786Z","iopub.status.idle":"2025-12-19T04:51:35.744500Z","shell.execute_reply.started":"2025-12-19T04:51:35.729764Z","shell.execute_reply":"2025-12-19T04:51:35.743721Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# 2. Build the BYOL model","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Encoder (ResNet18)","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\n\ndef get_encoder():\n    resnet = models.resnet18(weights=None)\n    resnet.fc = torch.nn.Identity()\n    return resnet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:51:35.745958Z","iopub.execute_input":"2025-12-19T04:51:35.746159Z","iopub.status.idle":"2025-12-19T04:51:35.754544Z","shell.execute_reply.started":"2025-12-19T04:51:35.746140Z","shell.execute_reply":"2025-12-19T04:51:35.754000Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 2.2 Projection head","metadata":{}},{"cell_type":"code","source":"class MLP(torch.nn.Module):\n    def __init__(self, in_dim, hidden_dim=512, out_dim=256):\n        super().__init__()\n        self.net = torch.nn.Sequential(\n            torch.nn.Linear(in_dim, hidden_dim),\n            torch.nn.BatchNorm1d(hidden_dim),\n            torch.nn.ReLU(),\n            torch.nn.Linear(hidden_dim, out_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\npredictor = MLP(256, 512, 256)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:51:35.755438Z","iopub.execute_input":"2025-12-19T04:51:35.755707Z","iopub.status.idle":"2025-12-19T04:51:35.774038Z","shell.execute_reply.started":"2025-12-19T04:51:35.755675Z","shell.execute_reply":"2025-12-19T04:51:35.773476Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 2.3 BYOL model","metadata":{}},{"cell_type":"code","source":"import copy\nimport torch.nn.functional as F\n\nclass BYOL(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.online_encoder = get_encoder()\n        self.target_encoder = copy.deepcopy(self.online_encoder)\n\n        self.online_proj = MLP(512)\n        self.target_proj = MLP(512)\n\n        self.predictor = MLP(256, 512, 256)\n\n        for p in self.target_encoder.parameters():\n            p.requires_grad = False\n        for p in self.target_proj.parameters():\n            p.requires_grad = False\n\n    @torch.no_grad()\n    def update_target(self, m=0.996):\n        for o, t in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\n            t.data = t.data * m + o.data * (1 - m)\n\n        for o, t in zip(self.online_proj.parameters(), self.target_proj.parameters()):\n            t.data = t.data * m + o.data * (1 - m)\n\n    def forward(self, v1, v2):\n        o1 = self.predictor(self.online_proj(self.online_encoder(v1)))\n        o2 = self.predictor(self.online_proj(self.online_encoder(v2)))\n\n        with torch.no_grad():\n            t1 = self.target_proj(self.target_encoder(v1))\n            t2 = self.target_proj(self.target_encoder(v2))\n\n        o1 = F.normalize(o1, dim=1)\n        o2 = F.normalize(o2, dim=1)\n        t1 = F.normalize(t1, dim=1)\n        t2 = F.normalize(t2, dim=1)\n\n        loss = 2 - 2 * (\n            (o1 * t2).sum(dim=1).mean() +\n            (o2 * t1).sum(dim=1).mean()\n        ) / 2\n\n        return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:51:35.774869Z","iopub.execute_input":"2025-12-19T04:51:35.775133Z","iopub.status.idle":"2025-12-19T04:51:35.785167Z","shell.execute_reply.started":"2025-12-19T04:51:35.775104Z","shell.execute_reply":"2025-12-19T04:51:35.784448Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# 3. Training loop ","metadata":{}},{"cell_type":"code","source":"dataset = STL10BYOL(\n    root=\"./data\",\n    split=\"unlabeled\",\n    download=True,\n    simclr_transform=byol_transform\n)\n\nloader = DataLoader(\n    dataset,\n    batch_size=512,\n    shuffle=True,\n    num_workers=4,\n    drop_last=True,\n    pin_memory=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:51:35.786070Z","iopub.execute_input":"2025-12-19T04:51:35.786302Z","iopub.status.idle":"2025-12-19T04:53:39.364437Z","shell.execute_reply.started":"2025-12-19T04:51:35.786281Z","shell.execute_reply":"2025-12-19T04:53:39.363614Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2.64G/2.64G [01:29<00:00, 29.4MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model = BYOL().cuda()\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=3e-4\n)\n\nscaler = torch.cuda.amp.GradScaler()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:53:39.365449Z","iopub.execute_input":"2025-12-19T04:53:39.365719Z","iopub.status.idle":"2025-12-19T04:53:39.859316Z","shell.execute_reply.started":"2025-12-19T04:53:39.365689Z","shell.execute_reply":"2025-12-19T04:53:39.858403Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/2207813503.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for epoch in range(50):\n    model.train()\n    total_loss = 0\n\n    for v1, v2 in loader:\n        v1, v2 = v1.cuda(), v2.cuda()\n\n        with torch.cuda.amp.autocast():\n            loss = model(v1, v2)\n\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        model.update_target()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch}: BYOL Loss = {total_loss/len(loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:53:39.860390Z","iopub.execute_input":"2025-12-19T04:53:39.860721Z","iopub.status.idle":"2025-12-19T08:43:59.672683Z","shell.execute_reply.started":"2025-12-19T04:53:39.860686Z","shell.execute_reply":"2025-12-19T08:43:59.671827Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/1460992765.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: BYOL Loss = 0.6487\nEpoch 1: BYOL Loss = 0.4233\nEpoch 2: BYOL Loss = 0.3506\nEpoch 3: BYOL Loss = 0.3216\nEpoch 4: BYOL Loss = 0.3132\nEpoch 5: BYOL Loss = 0.3025\nEpoch 6: BYOL Loss = 0.3017\nEpoch 7: BYOL Loss = 0.2914\nEpoch 8: BYOL Loss = 0.2850\nEpoch 9: BYOL Loss = 0.2802\nEpoch 10: BYOL Loss = 0.2762\nEpoch 11: BYOL Loss = 0.2730\nEpoch 12: BYOL Loss = 0.2684\nEpoch 13: BYOL Loss = 0.2644\nEpoch 14: BYOL Loss = 0.2643\nEpoch 15: BYOL Loss = 0.2597\nEpoch 16: BYOL Loss = 0.2610\nEpoch 17: BYOL Loss = 0.2574\nEpoch 18: BYOL Loss = 0.2575\nEpoch 19: BYOL Loss = 0.2539\nEpoch 20: BYOL Loss = 0.2533\nEpoch 21: BYOL Loss = 0.2531\nEpoch 22: BYOL Loss = 0.2509\nEpoch 23: BYOL Loss = 0.2498\nEpoch 24: BYOL Loss = 0.2481\nEpoch 25: BYOL Loss = 0.2481\nEpoch 26: BYOL Loss = 0.2485\nEpoch 27: BYOL Loss = 0.2502\nEpoch 28: BYOL Loss = 0.2503\nEpoch 29: BYOL Loss = 0.2500\nEpoch 30: BYOL Loss = 0.2519\nEpoch 31: BYOL Loss = 0.2515\nEpoch 32: BYOL Loss = 0.2523\nEpoch 33: BYOL Loss = 0.2524\nEpoch 34: BYOL Loss = 0.2528\nEpoch 35: BYOL Loss = 0.2540\nEpoch 36: BYOL Loss = 0.2549\nEpoch 37: BYOL Loss = 0.2555\nEpoch 38: BYOL Loss = 0.2566\nEpoch 39: BYOL Loss = 0.2586\nEpoch 40: BYOL Loss = 0.2605\nEpoch 41: BYOL Loss = 0.2613\nEpoch 42: BYOL Loss = 0.2621\nEpoch 43: BYOL Loss = 0.2643\nEpoch 44: BYOL Loss = 0.2634\nEpoch 45: BYOL Loss = 0.2667\nEpoch 46: BYOL Loss = 0.2677\nEpoch 47: BYOL Loss = 0.2687\nEpoch 48: BYOL Loss = 0.2682\nEpoch 49: BYOL Loss = 0.2696\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"torch.save(\n    model.online_encoder.state_dict(),\n    \"encoder_byol.pth\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:43:59.675543Z","iopub.execute_input":"2025-12-19T08:43:59.675831Z","iopub.status.idle":"2025-12-19T08:43:59.751440Z","shell.execute_reply.started":"2025-12-19T08:43:59.675803Z","shell.execute_reply":"2025-12-19T08:43:59.750644Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# 5. Validation\n5.1 Linear probing\n5.2 KNN testing","metadata":{}},{"cell_type":"code","source":"encoder = get_encoder().cuda()\nencoder.load_state_dict(torch.load(\"encoder_byol.pth\"))\nencoder = encoder.cuda()\n\nfor param in encoder.parameters():\n    param.requires_grad = False\n\nencoder.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:43:59.752340Z","iopub.execute_input":"2025-12-19T08:43:59.752632Z","iopub.status.idle":"2025-12-19T08:43:59.975208Z","shell.execute_reply.started":"2025-12-19T08:43:59.752607Z","shell.execute_reply":"2025-12-19T08:43:59.974680Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Identity()\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"### 5.1 Linear probing","metadata":{}},{"cell_type":"code","source":"linear_head = torch.nn.Linear(512, 10).cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:43:59.976002Z","iopub.execute_input":"2025-12-19T08:43:59.976248Z","iopub.status.idle":"2025-12-19T08:43:59.980675Z","shell.execute_reply.started":"2025-12-19T08:43:59.976219Z","shell.execute_reply":"2025-12-19T08:43:59.980122Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from torchvision.datasets import STL10\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize(96),\n    transforms.ToTensor()\n])\n\ntrain_set = STL10(\n    root=\"./data\",\n    split=\"train\",\n    download=True,\n    transform=transform\n)\n\ntest_set = STL10(\n    root=\"./data\",\n    split=\"test\",\n    download=True,\n    transform=transform\n)\n\ntrain_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=4)\ntest_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:43:59.981425Z","iopub.execute_input":"2025-12-19T08:43:59.981915Z","iopub.status.idle":"2025-12-19T08:44:10.918241Z","shell.execute_reply.started":"2025-12-19T08:43:59.981888Z","shell.execute_reply":"2025-12-19T08:44:10.917667Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(linear_head.parameters(), lr=1e-3)\n\n\nfor epoch in range(20):\n    linear_head.train()\n    total_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.cuda(), y.cuda()\n\n        with torch.no_grad():\n            features = encoder(x)\n\n        logits = linear_head(features)\n        loss = criterion(logits, y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch}: Loss = {total_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:44:10.919054Z","iopub.execute_input":"2025-12-19T08:44:10.919312Z","iopub.status.idle":"2025-12-19T08:44:42.916908Z","shell.execute_reply.started":"2025-12-19T08:44:10.919281Z","shell.execute_reply":"2025-12-19T08:44:42.915496Z"}},"outputs":[{"name":"stdout","text":"Epoch 0: Loss = 1.7923\nEpoch 1: Loss = 1.2001\nEpoch 2: Loss = 1.0359\nEpoch 3: Loss = 0.9575\nEpoch 4: Loss = 0.9139\nEpoch 5: Loss = 0.8863\nEpoch 6: Loss = 0.8642\nEpoch 7: Loss = 0.8492\nEpoch 8: Loss = 0.8361\nEpoch 9: Loss = 0.8252\nEpoch 10: Loss = 0.8112\nEpoch 11: Loss = 0.8055\nEpoch 12: Loss = 0.7970\nEpoch 13: Loss = 0.7868\nEpoch 14: Loss = 0.7814\nEpoch 15: Loss = 0.7779\nEpoch 16: Loss = 0.7652\nEpoch 17: Loss = 0.7651\nEpoch 18: Loss = 0.7590\nEpoch 19: Loss = 0.7541\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"linear_head.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for x, y in test_loader:\n        x, y = x.cuda(), y.cuda()\n        features = encoder(x)\n        logits = linear_head(features)\n        preds = logits.argmax(dim=1)\n\n        correct += (preds == y).sum().item()\n        total += y.size(0)\n\nacc = correct / total * 100\nprint(f\"Linear Probe Accuracy: {acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:44:42.918060Z","iopub.execute_input":"2025-12-19T08:44:42.918327Z","iopub.status.idle":"2025-12-19T08:44:45.233716Z","shell.execute_reply.started":"2025-12-19T08:44:42.918297Z","shell.execute_reply":"2025-12-19T08:44:45.232608Z"}},"outputs":[{"name":"stdout","text":"Linear Probe Accuracy: 70.14%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 5.2 KNN testing","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef extract_features(loader):\n    feats = []\n    labels = []\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.cuda()\n            f = encoder(x)\n            feats.append(f.cpu())\n            labels.append(y)\n\n    return torch.cat(feats), torch.cat(labels)\n\ntrain_feats, train_labels = extract_features(train_loader)\ntest_feats, test_labels = extract_features(test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:44:45.235219Z","iopub.execute_input":"2025-12-19T08:44:45.235564Z","iopub.status.idle":"2025-12-19T08:44:49.113251Z","shell.execute_reply.started":"2025-12-19T08:44:45.235532Z","shell.execute_reply":"2025-12-19T08:44:49.112450Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_feats = torch.nn.functional.normalize(train_feats, dim=1)\ntest_feats = torch.nn.functional.normalize(test_feats, dim=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:44:49.114495Z","iopub.execute_input":"2025-12-19T08:44:49.114855Z","iopub.status.idle":"2025-12-19T08:44:49.135233Z","shell.execute_reply.started":"2025-12-19T08:44:49.114825Z","shell.execute_reply":"2025-12-19T08:44:49.134525Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def knn_accuracy(train_feats, train_labels, test_feats, test_labels, k=20):\n    correct = 0\n\n    for i in range(test_feats.size(0)):\n        sim = torch.matmul(train_feats, test_feats[i])\n        topk = sim.topk(k).indices\n        pred = train_labels[topk].mode()[0]\n\n        correct += (pred == test_labels[i]).item()\n\n    return correct / test_feats.size(0) * 100\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:44:49.136195Z","iopub.execute_input":"2025-12-19T08:44:49.136493Z","iopub.status.idle":"2025-12-19T08:44:49.141305Z","shell.execute_reply.started":"2025-12-19T08:44:49.136471Z","shell.execute_reply":"2025-12-19T08:44:49.140720Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"acc_knn = knn_accuracy(\n    train_feats, train_labels,\n    test_feats, test_labels,\n    k=20\n)\n\nprint(f\"k-NN Accuracy (k=20): {acc_knn:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:44:49.142223Z","iopub.execute_input":"2025-12-19T08:44:49.142466Z","iopub.status.idle":"2025-12-19T08:44:51.742559Z","shell.execute_reply.started":"2025-12-19T08:44:49.142435Z","shell.execute_reply":"2025-12-19T08:44:51.741912Z"}},"outputs":[{"name":"stdout","text":"k-NN Accuracy (k=20): 68.66%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}