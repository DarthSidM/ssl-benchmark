{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BYOL from Scratch\n\n## This notebook implements BYOL end‑to‑end\n\n1. Build augmentations\n\n2. Build the BYOL model\n\n3. Train on STL‑10 (unlabeled)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.datasets import STL10\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nimport random\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:15.568740Z","iopub.execute_input":"2025-12-22T13:14:15.568980Z","iopub.status.idle":"2025-12-22T13:14:23.930399Z","shell.execute_reply.started":"2025-12-22T13:14:15.568959Z","shell.execute_reply":"2025-12-22T13:14:23.929832Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:27.165646Z","iopub.execute_input":"2025-12-22T13:14:27.166253Z","iopub.status.idle":"2025-12-22T13:14:27.176812Z","shell.execute_reply.started":"2025-12-22T13:14:27.166224Z","shell.execute_reply":"2025-12-22T13:14:27.176263Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# 1. BYOL Augmentations","metadata":{}},{"cell_type":"code","source":"class BYOLAugmentations:\n    def __init__(self, image_size=96):\n        self.transform = transforms.Compose([\n            transforms.RandomResizedCrop(image_size),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomApply([\n                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n            ], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.GaussianBlur(kernel_size=9),\n            transforms.ToTensor(),\n        ])\n\n\n    def __call__(self, x):\n        v1 = self.transform(x)\n        v2 = self.transform(x)\n        return v1, v2\n\nbyol_transform = BYOLAugmentations()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:30.694899Z","iopub.execute_input":"2025-12-22T13:14:30.695653Z","iopub.status.idle":"2025-12-22T13:14:30.701507Z","shell.execute_reply.started":"2025-12-22T13:14:30.695625Z","shell.execute_reply":"2025-12-22T13:14:30.700882Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class STL10BYOL(STL10):\n    def __init__(self, *args, simclr_transform=None, **kwargs):\n        super().__init__(*args, transform=None, **kwargs)\n        self.simclr_transform = simclr_transform\n\n    def __getitem__(self, index):\n        img, _ = super().__getitem__(index)  # raw PIL image\n        v1, v2 = self.simclr_transform(img)\n        return v1, v2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:32.846369Z","iopub.execute_input":"2025-12-22T13:14:32.846951Z","iopub.status.idle":"2025-12-22T13:14:32.851151Z","shell.execute_reply.started":"2025-12-22T13:14:32.846924Z","shell.execute_reply":"2025-12-22T13:14:32.850480Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# 2. Build the BYOL model","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Encoder (ResNet18)","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\n\ndef get_encoder():\n    resnet = models.resnet18(weights=None)\n    resnet.fc = torch.nn.Identity()\n    return resnet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:36.756302Z","iopub.execute_input":"2025-12-22T13:14:36.757067Z","iopub.status.idle":"2025-12-22T13:14:36.760685Z","shell.execute_reply.started":"2025-12-22T13:14:36.757036Z","shell.execute_reply":"2025-12-22T13:14:36.759973Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 2.2 Projection head","metadata":{}},{"cell_type":"code","source":"class MLP(torch.nn.Module):\n    def __init__(self, in_dim, hidden_dim=512, out_dim=256):\n        super().__init__()\n        self.net = torch.nn.Sequential(\n            torch.nn.Linear(in_dim, hidden_dim),\n            torch.nn.BatchNorm1d(hidden_dim),\n            torch.nn.ReLU(),\n            torch.nn.Linear(hidden_dim, out_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\npredictor = MLP(256, 512, 256)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:39.992528Z","iopub.execute_input":"2025-12-22T13:14:39.993242Z","iopub.status.idle":"2025-12-22T13:14:40.007593Z","shell.execute_reply.started":"2025-12-22T13:14:39.993211Z","shell.execute_reply":"2025-12-22T13:14:40.006913Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 2.3 BYOL model","metadata":{}},{"cell_type":"code","source":"import copy\nimport torch.nn.functional as F\n\nclass BYOL(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.online_encoder = get_encoder()\n        self.target_encoder = copy.deepcopy(self.online_encoder)\n\n        self.online_proj = MLP(512)\n        self.target_proj = MLP(512)\n\n        self.predictor = MLP(256, 512, 256)\n\n        for p in self.target_encoder.parameters():\n            p.requires_grad = False\n        for p in self.target_proj.parameters():\n            p.requires_grad = False\n\n    @torch.no_grad()\n    def update_target(self, m=0.996):\n        for o, t in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\n            t.data = t.data * m + o.data * (1 - m)\n\n        for o, t in zip(self.online_proj.parameters(), self.target_proj.parameters()):\n            t.data = t.data * m + o.data * (1 - m)\n\n    def forward(self, v1, v2):\n        o1 = self.predictor(self.online_proj(self.online_encoder(v1)))\n        o2 = self.predictor(self.online_proj(self.online_encoder(v2)))\n\n        with torch.no_grad():\n            t1 = self.target_proj(self.target_encoder(v1))\n            t2 = self.target_proj(self.target_encoder(v2))\n\n        o1 = F.normalize(o1, dim=1)\n        o2 = F.normalize(o2, dim=1)\n        t1 = F.normalize(t1, dim=1)\n        t2 = F.normalize(t2, dim=1)\n\n        loss = 2 - 2 * (\n            (o1 * t2).sum(dim=1).mean() +\n            (o2 * t1).sum(dim=1).mean()\n        ) / 2\n\n        return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:44.583700Z","iopub.execute_input":"2025-12-22T13:14:44.584001Z","iopub.status.idle":"2025-12-22T13:14:44.592635Z","shell.execute_reply.started":"2025-12-22T13:14:44.583976Z","shell.execute_reply":"2025-12-22T13:14:44.591954Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# 3. Training loop ","metadata":{}},{"cell_type":"code","source":"dataset = STL10BYOL(\n    root=\"./data\",\n    split=\"unlabeled\",\n    download=True,\n    simclr_transform=byol_transform\n)\n\nloader = DataLoader(\n    dataset,\n    batch_size=512,\n    shuffle=True,\n    num_workers=4,\n    drop_last=True,\n    pin_memory=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:47.203884Z","iopub.execute_input":"2025-12-22T13:14:47.204157Z","iopub.status.idle":"2025-12-22T13:17:42.002673Z","shell.execute_reply.started":"2025-12-22T13:14:47.204132Z","shell.execute_reply":"2025-12-22T13:17:42.001862Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2.64G/2.64G [02:20<00:00, 18.8MB/s] \n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model = BYOL().cuda()\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=3e-4\n)\n\nscaler = torch.cuda.amp.GradScaler()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:18:44.417001Z","iopub.execute_input":"2025-12-22T13:18:44.417728Z","iopub.status.idle":"2025-12-22T13:18:44.910343Z","shell.execute_reply.started":"2025-12-22T13:18:44.417698Z","shell.execute_reply":"2025-12-22T13:18:44.909488Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/2207813503.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"for epoch in range(50):\n    model.train()\n    total_loss = 0\n\n    for v1, v2 in loader:\n        v1, v2 = v1.cuda(), v2.cuda()\n\n        with torch.cuda.amp.autocast():\n            loss = model(v1, v2)\n\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        model.update_target()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch}: BYOL Loss = {total_loss/len(loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:18:47.141730Z","iopub.execute_input":"2025-12-22T13:18:47.142401Z","iopub.status.idle":"2025-12-22T16:59:00.385094Z","shell.execute_reply.started":"2025-12-22T13:18:47.142372Z","shell.execute_reply":"2025-12-22T16:59:00.384289Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/1460992765.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: BYOL Loss = 0.6509\nEpoch 1: BYOL Loss = 0.4477\nEpoch 2: BYOL Loss = 0.3755\nEpoch 3: BYOL Loss = 0.3621\nEpoch 4: BYOL Loss = 0.3554\nEpoch 5: BYOL Loss = 0.3504\nEpoch 6: BYOL Loss = 0.3458\nEpoch 7: BYOL Loss = 0.3390\nEpoch 8: BYOL Loss = 0.3325\nEpoch 9: BYOL Loss = 0.3283\nEpoch 10: BYOL Loss = 0.3240\nEpoch 11: BYOL Loss = 0.3185\nEpoch 12: BYOL Loss = 0.3139\nEpoch 13: BYOL Loss = 0.3065\nEpoch 14: BYOL Loss = 0.3014\nEpoch 15: BYOL Loss = 0.2951\nEpoch 16: BYOL Loss = 0.2912\nEpoch 17: BYOL Loss = 0.2860\nEpoch 18: BYOL Loss = 0.2829\nEpoch 19: BYOL Loss = 0.2785\nEpoch 20: BYOL Loss = 0.2782\nEpoch 21: BYOL Loss = 0.2768\nEpoch 22: BYOL Loss = 0.2783\nEpoch 23: BYOL Loss = 0.2758\nEpoch 24: BYOL Loss = 0.2742\nEpoch 25: BYOL Loss = 0.2734\nEpoch 26: BYOL Loss = 0.2739\nEpoch 27: BYOL Loss = 0.2729\nEpoch 28: BYOL Loss = 0.2731\nEpoch 29: BYOL Loss = 0.2725\nEpoch 30: BYOL Loss = 0.2712\nEpoch 31: BYOL Loss = 0.2725\nEpoch 32: BYOL Loss = 0.2706\nEpoch 33: BYOL Loss = 0.2724\nEpoch 34: BYOL Loss = 0.2719\nEpoch 35: BYOL Loss = 0.2721\nEpoch 36: BYOL Loss = 0.2733\nEpoch 37: BYOL Loss = 0.2713\nEpoch 38: BYOL Loss = 0.2700\nEpoch 39: BYOL Loss = 0.2697\nEpoch 40: BYOL Loss = 0.2702\nEpoch 41: BYOL Loss = 0.2704\nEpoch 42: BYOL Loss = 0.2704\nEpoch 43: BYOL Loss = 0.2708\nEpoch 44: BYOL Loss = 0.2713\nEpoch 45: BYOL Loss = 0.2717\nEpoch 46: BYOL Loss = 0.2721\nEpoch 47: BYOL Loss = 0.2725\nEpoch 48: BYOL Loss = 0.2722\nEpoch 49: BYOL Loss = 0.2724\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"torch.save(\n    model.online_encoder.state_dict(),\n    \"encoder_byol.pth\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:04:49.365669Z","iopub.execute_input":"2025-12-22T17:04:49.366250Z","iopub.status.idle":"2025-12-22T17:04:49.461868Z","shell.execute_reply.started":"2025-12-22T17:04:49.366223Z","shell.execute_reply":"2025-12-22T17:04:49.461094Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# 5. Validation\n5.1 Linear probing\n5.2 KNN testing","metadata":{}},{"cell_type":"code","source":"encoder = get_encoder().cuda()\nencoder.load_state_dict(torch.load(\"encoder_byol.pth\"))\nencoder = encoder.cuda()\n\nfor param in encoder.parameters():\n    param.requires_grad = False\n\nencoder.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:04:51.521879Z","iopub.execute_input":"2025-12-22T17:04:51.522412Z","iopub.status.idle":"2025-12-22T17:04:51.738664Z","shell.execute_reply.started":"2025-12-22T17:04:51.522385Z","shell.execute_reply":"2025-12-22T17:04:51.738035Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Identity()\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### 5.1 Linear probing","metadata":{}},{"cell_type":"code","source":"linear_head = torch.nn.Linear(512, 10).cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:04:55.422378Z","iopub.execute_input":"2025-12-22T17:04:55.422959Z","iopub.status.idle":"2025-12-22T17:04:55.427155Z","shell.execute_reply.started":"2025-12-22T17:04:55.422933Z","shell.execute_reply":"2025-12-22T17:04:55.426396Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from torchvision.datasets import STL10\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize(96),\n    transforms.ToTensor()\n])\n\ntrain_set = STL10(\n    root=\"./data\",\n    split=\"train\",\n    download=True,\n    transform=transform\n)\n\ntest_set = STL10(\n    root=\"./data\",\n    split=\"test\",\n    download=True,\n    transform=transform\n)\n\ntrain_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=4)\ntest_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:04:57.522109Z","iopub.execute_input":"2025-12-22T17:04:57.522842Z","iopub.status.idle":"2025-12-22T17:05:08.429391Z","shell.execute_reply.started":"2025-12-22T17:04:57.522811Z","shell.execute_reply":"2025-12-22T17:05:08.428815Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(linear_head.parameters(), lr=1e-3)\n\n\nfor epoch in range(20):\n    linear_head.train()\n    total_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.cuda(), y.cuda()\n\n        with torch.no_grad():\n            features = encoder(x)\n\n        logits = linear_head(features)\n        loss = criterion(logits, y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch}: Loss = {total_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:05:12.436122Z","iopub.execute_input":"2025-12-22T17:05:12.436842Z","iopub.status.idle":"2025-12-22T17:05:45.065165Z","shell.execute_reply.started":"2025-12-22T17:05:12.436815Z","shell.execute_reply":"2025-12-22T17:05:45.064228Z"}},"outputs":[{"name":"stdout","text":"Epoch 0: Loss = 1.7736\nEpoch 1: Loss = 1.2320\nEpoch 2: Loss = 1.0625\nEpoch 3: Loss = 0.9862\nEpoch 4: Loss = 0.9476\nEpoch 5: Loss = 0.9239\nEpoch 6: Loss = 0.8964\nEpoch 7: Loss = 0.8806\nEpoch 8: Loss = 0.8657\nEpoch 9: Loss = 0.8570\nEpoch 10: Loss = 0.8492\nEpoch 11: Loss = 0.8392\nEpoch 12: Loss = 0.8309\nEpoch 13: Loss = 0.8223\nEpoch 14: Loss = 0.8169\nEpoch 15: Loss = 0.8132\nEpoch 16: Loss = 0.8042\nEpoch 17: Loss = 0.7997\nEpoch 18: Loss = 0.7987\nEpoch 19: Loss = 0.7909\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"linear_head.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for x, y in test_loader:\n        x, y = x.cuda(), y.cuda()\n        features = encoder(x)\n        logits = linear_head(features)\n        preds = logits.argmax(dim=1)\n\n        correct += (preds == y).sum().item()\n        total += y.size(0)\n\nacc = correct / total * 100\nprint(f\"Linear Probe Accuracy: {acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:06:11.395376Z","iopub.execute_input":"2025-12-22T17:06:11.396205Z","iopub.status.idle":"2025-12-22T17:06:13.696736Z","shell.execute_reply.started":"2025-12-22T17:06:11.396172Z","shell.execute_reply":"2025-12-22T17:06:13.695888Z"}},"outputs":[{"name":"stdout","text":"Linear Probe Accuracy: 69.58%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## 5.2 KNN testing","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef extract_features(loader):\n    feats = []\n    labels = []\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.cuda()\n            f = encoder(x)\n            feats.append(f.cpu())\n            labels.append(y)\n\n    return torch.cat(feats), torch.cat(labels)\n\ntrain_feats, train_labels = extract_features(train_loader)\ntest_feats, test_labels = extract_features(test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:06:16.459723Z","iopub.execute_input":"2025-12-22T17:06:16.460357Z","iopub.status.idle":"2025-12-22T17:06:20.312011Z","shell.execute_reply.started":"2025-12-22T17:06:16.460327Z","shell.execute_reply":"2025-12-22T17:06:20.311212Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_feats = torch.nn.functional.normalize(train_feats, dim=1)\ntest_feats = torch.nn.functional.normalize(test_feats, dim=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:06:22.419208Z","iopub.execute_input":"2025-12-22T17:06:22.419760Z","iopub.status.idle":"2025-12-22T17:06:22.443647Z","shell.execute_reply.started":"2025-12-22T17:06:22.419729Z","shell.execute_reply":"2025-12-22T17:06:22.443081Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def knn_accuracy(train_feats, train_labels, test_feats, test_labels, k=20):\n    correct = 0\n\n    for i in range(test_feats.size(0)):\n        sim = torch.matmul(train_feats, test_feats[i])\n        topk = sim.topk(k).indices\n        pred = train_labels[topk].mode()[0]\n\n        correct += (pred == test_labels[i]).item()\n\n    return correct / test_feats.size(0) * 100\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:06:23.839667Z","iopub.execute_input":"2025-12-22T17:06:23.840254Z","iopub.status.idle":"2025-12-22T17:06:23.844785Z","shell.execute_reply.started":"2025-12-22T17:06:23.840228Z","shell.execute_reply":"2025-12-22T17:06:23.844201Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"acc_knn = knn_accuracy(\n    train_feats, train_labels,\n    test_feats, test_labels,\n    k=20\n)\n\nprint(f\"k-NN Accuracy (k=20): {acc_knn:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:06:25.378677Z","iopub.execute_input":"2025-12-22T17:06:25.378926Z","iopub.status.idle":"2025-12-22T17:06:27.955925Z","shell.execute_reply.started":"2025-12-22T17:06:25.378893Z","shell.execute_reply":"2025-12-22T17:06:27.955143Z"}},"outputs":[{"name":"stdout","text":"k-NN Accuracy (k=20): 67.58%\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}